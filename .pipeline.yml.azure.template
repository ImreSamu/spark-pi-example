pipeline:
  create_cluster:
    image: banzaicloud/plugin-pipeline-client:0.2.0
    cluster_name: "spark-pi-cluster"
    cluster_provider: "azure"
    cluster_location: "eastus"
    azure_resource_group: "az_resource_group"

    secrets: [plugin_endpoint, plugin_username, plugin_password]

  install_monitoring
    deployment_name: "banzaicloud-stable/pipeline-cluster-monitor"
    deployment_release_name: "monitor"
    deployment_values:
      prometheus:
        nodeExporter:
          enabled: true

    secrets: [plugin_endpoint, plugin_username, plugin_password]

  install_spark_history_server:
    image: banzaicloud/plugin-pipeline-client:0.2.0

    deployment_name: "banzaicloud-stable/spark-hs"
    deployment_release_name: "historyserver"
    deployment_values:
      app:
        logDirectory: "wasb://spark-k8-logs@{{ .PLUGIN_AZURE_STORAGE_ACCOUNT }}.blob.core.windows.net/eventLog"
        azure_storage_account: "{{ .PLUGIN_AZURE_STORAGE_ACCOUNT }}"
        azure_storage_account_access_key: "{{ .PLUGIN_AZURE_STORAGE_ACCOUNT_ACCESS_KEY }}"

    secrets: [plugin_endpoint, plugin_username, plugin_password, plugin_azure_storage_account, plugin_azure_storage_account_access_key]

  install_spark_resources
    image: banzaicloud/plugin-pipeline-client:0.2.0

    deployment_name: "banzaicloud-stable/spark"
    deployment_release_name: "spark"

  remote_checkout:
    image: banzaicloud/plugin-k8s-proxy:0.2.0
    original_image: plugins/git

  remote_build:
    image: banzaicloud/plugin-k8s-proxy:0.2.0
    original_image: denvazh/scala:2.11.8
    original_commands:
      - sbt clean package

  run:
    image: banzaicloud/plugin-k8s-proxy:0.2.0
    original_image: banzaicloud/plugin-spark-submit-k8s:0.2.0

    pod_service_account: spark
    pull: true
    spark_deploy_mode: cluster

    spark_class: banzaicloud.SparkPi
    spark_app_name: sparkpi
    spark_local_dir: /tmp/spark-local

    spark_kubernetes_driver_docker_image: banzaicloud/spark-driver:v2.2.0-k8s-1.0.197
    spark_kubernetes_executor_docker_image: banzaicloud/spark-executor:v2.2.0-k8s-1.0.197
    spark_kubernetes_initcontainer_docker_image: banzaicloud/spark-init:v2.2.0-k8s-1.0.197
    spark_kubernetes_resourcestagingserver_uri: http://spark-rss:10000
    spark_kubernetes_resourcestagingserver_internal_uri: http://spark-rss:10000

    spark_kubernetes_shuffle_labels: "app=spark-shuffle-service,spark-version=2.2.0"
    spark_kubernetes_authenticate_driver_serviceaccount_name: "spark"
    spark_metrics_conf: /opt/spark/conf/metrics.properties

    spark_eventLog_enabled: true
    spark_eventLog_dir: "wasb://spark-k8-logs@sparklogstore.blob.core.windows.net/eventLog"

    spark_app_source: target/spark-pi-1.0-SNAPSHOT.jar
    spark_app_args: 1000

    secrets: [plugin_azure_storage_account, plugin_azure_storage_account_access_key]